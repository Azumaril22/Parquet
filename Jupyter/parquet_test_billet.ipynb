{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequis :\n",
    "===========\n",
    "Téléchargement\n",
    "----------------\n",
    "wget ftp://ftp.1000genomes.ebi.ac.uk/vol1/ftp/data_collections/1000_genomes_project/release/20190312_biallelic_SNV_and_INDEL/ALL.wgs.shapeit2_integrated_snvindels_v2a.GRCh38.27022019.sites.vcf.gz\n",
    "\n",
    "Decompression\n",
    "-------------\n",
    "gzip -d ALL.wgs.shapeit2_integrated_snvindels_v2a.GRCh38.27022019.sites.vcf.gz\n",
    "\n",
    "Créer un dossier db à la racine du projet au même niveau que parquet_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lisez le fichier VCF comme un CSV avec pl.scan_csv\n",
    "- Sélectionner les colonnes CHROM, POS, REF, ALT\n",
    "- Écrire le fichier variants.parquet avec sink_parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_829840/1612784494.py:11: DeprecationWarning: The old streaming engine is being deprecated and will soon be replaced by the new streaming engine. Starting Polars version 1.23.0 and until the new streaming engine is released, the old streaming engine may become less usable. For people who rely on the old streaming engine, it is suggested to pin your version to before 1.23.0.\n",
      "\n",
      "More information on the new streaming engine: https://github.com/pola-rs/polars/issues/20947\n",
      "  ).sink_parquet(                         # Écriture du fichier parquet\n"
     ]
    }
   ],
   "source": [
    "pl.scan_csv(\n",
    "    \"../Datasets/ALL.wgs.shapeit2_integrated_snvindels_v2a.GRCh38.27022019.sites.vcf\",\n",
    "    skip_rows=40,                       # Je saute les 40 premieres lignes de commentaires\n",
    "    separator=\"\\t\",                           # Séparateur TSV\n",
    "    schema_overrides={\"#CHROM\": pl.Utf8},         # Je précise le type, sinon la colonne est considérée comme un int\n",
    ").select([                              # Je sélectionne les colonnes souhaitées\n",
    "    pl.col(\"#CHROM\").alias(\"CHROM\"),    # Je renomme ici la colonne avec alias\n",
    "    pl.col(\"POS\"),\n",
    "    pl.col(\"REF\"),\n",
    "    pl.col(\"ALT\")]\n",
    ").sink_parquet(                         # Écriture du fichier parquet \n",
    "    \"../db/variants.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Ce qu’il faut savoir sur le streaming avec Polars\n",
    "----------------------------------------------------\n",
    "Le moteur de streaming actuel (avant 1.23) fonctionne, mais il est marqué comme \"deprecated\" car l’équipe Polars travaille sur une nouvelle version plus robuste.  \n",
    "Pour le moment, il n’y a pas d’alternative dans Polars pour gérer ce type de fichiers en streaming. Donc même si tu vois le warning, tu peux continuer à l’utiliser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Les fonctions scan_csv et sink_csv permettent de faire la transformation du VCF sans le charger en mémoire. \n",
    "- Regardez aussi les tailles du fichier. 225Mo pour le fichier parquet et 1.3Go pour son équivalent en CSV. \n",
    "- En effet, les fichiers parquets sont compressés naturellement du fait du modèle orienté colonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requête SQL avec DuckDB\n",
    "-----------------------\n",
    "À présent essayez de requêter sur ce fichier. Nous pourrions le faire avec pola.rs, mais nous allons plutôt faire une requête SQL en utilisant duckDB.\n",
    "\n",
    "Pour exécuter une requête SQL sur un fichier parquet, il suffit de considérer le fichier comme le nom d'une table SQL :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT count(*) FROM '../db/variants.parquet'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT * FROM '../db/variants.parquet' ORDER BY CHROM, POS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT * FROM '../db/variants.parquet' WHERE REF='A' ORDER BY CHROM, POS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À présent, essayons de faire plus compliqué en comptant le nombre de transitions et de transversions. C'est à dire, le nombre de combinaisons A>T, C>G etc ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "SELECT list_sort([ref,alt]) AS mut, COUNT(*) as count FROM '../db/variants.parquet' \n",
    "WHERE len(ref) = 1 AND len(alt)=1 GROUP BY mut\n",
    "\"\"\"\n",
    "\n",
    "duckdb.sql(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autres astuces\n",
    "==============\n",
    "Le partitionnement\n",
    "------------------\n",
    "Niveau performance, c'est déjà bluffant. Mais il existe différentes méthodes d'optimisation pour être plus performant suivant l'usage des données. Le partitionnement consiste à découper votre fichier parquet en plusieurs fichiers parquet depuis une ou plusieurs colonnes. Par exemple, je peux partitionner le fichier parquet variants.parquet par chromosomes. Si je dois chercher un variant sur le chromosome 8, je peux regarder uniquement dans le fichier correspondant. Inutile de parcourir les variants du chromosomes 2.\n",
    "\n",
    "Construisons une partition sur la colonne chromosome avec duckDB :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\n",
    "    \"COPY (SELECT * FROM 'db/variants.parquet') TO '../db/chromosomes' (FORMAT PARQUET, PARTITION_BY (CHROM))\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir exécuté cette requête, vous devriez avoir un dossier chromosomes contenant de nombreux fichiers triés par chromosomes.\n",
    "Pour sélectionner vos variants depuis ce dossier, il suffit d'utiliser le caractère étoile ou des expressions régulières pour sélectionner les sources de données souhaitées."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans l'exemple suivant, je sélectionne tous les variants à partir de tous les fichiers :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\"SELECT * FROM '../db/chromosomes/*/*.parquet'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
